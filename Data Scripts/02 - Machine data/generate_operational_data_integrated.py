"""
GenIMS Operations Module (Integrated) - ULTRA OPTIMIZED
Uses unified master registry - no independent master data creation
Generates: sensor_data, scada_machine_data, production_runs, maintenance_events, machine_faults, sensor_health
OPTIMIZED: Internal async/parallel processing for maximum performance
"""

import json
import pickle
import random
import os
from datetime import datetime, timedelta
from typing import Dict, List
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
import threading
import multiprocessing

class OperationsDataGenerator:
    """Generate operations data using master registry with ULTRA OPTIMIZED parallel processing"""
    
    def __init__(self):
        """Load master registry and initialize with parallel processing capabilities"""
        from pathlib import Path
        
        project_root = Path(__file__).parent.parent
        master_dir = project_root / "01 - Base Data"
        
        print("Loading master registry...")
        registry_file = master_dir / 'genims_master_registry.pkl'
        master_json_file = master_dir / 'genims_master_data.json'
        
        if not registry_file.exists():
            raise FileNotFoundError(f"Master registry not found: {registry_file}")
        if not master_json_file.exists():
            raise FileNotFoundError(f"Master data JSON not found: {master_json_file}")
        
        with open(registry_file, 'rb') as f:
            self.registry = pickle.load(f)
        
        # Get references from master data
        with open(master_json_file, 'r') as f:
            master_data = json.load(f)
        
        self.factories = {f['factory_id']: f for f in master_data['factories']}
        self.products = {p['product_id']: p for p in master_data['products']}
        self.employees = {e['employee_id']: e for e in master_data['employees']}
        self.customers = master_data['customers']
        self.shifts = master_data.get('shifts', [])  # Load shifts for FK references
        
        # Load master data that was already generated
        self.production_lines = master_data.get('production_lines', [])
        self.machines = master_data.get('machines', [])
        self.sensors = master_data.get('sensors', [])
        
        # Operational data only (NOT master data) - Thread-safe storage
        self.data = {
            'sensor_data': [],
            'scada_machine_data': [],
            'production_runs': [],
            'maintenance_events': [],
            'machine_faults': [],
            'sensor_health': [],
        }
        
        # Thread safety and parallel processing configuration
        self.data_lock = threading.Lock()
        self.counters = self.registry['id_counters'].copy()
        
        # Enable ULTRA-FAST parallel processing by default (overriding environment)
        self.parallel_enabled = True  # Always enable for maximum performance
        self.worker_count = min(8, max(2, multiprocessing.cpu_count() - 1))  # Use 2-8 workers optimally
        self.batch_size = int(os.getenv('BATCH_SIZE', '150000'))
        
        print(f"ðŸš€ ULTRA-FAST PARALLEL MODE: {self.worker_count} workers, batch_size={self.batch_size}")
        print(f"   CPU cores available: {multiprocessing.cpu_count()}, Using {self.worker_count} for generation")
    
    def get_next_id(self, prefix: str) -> str:
        """Get next ID (thread-safe)"""
        with self.data_lock:
            if prefix not in self.counters:
                self.counters[prefix] = 1
            id_val = self.counters[prefix]
            self.counters[prefix] += 1
            return f"{prefix}-{id_val:06d}"
    
    def _generate_sensor_data_chunk(self, sensor_chunk: List[dict], chunk_id: int, start_id: int) -> List[dict]:
        """Generate sensor data for a chunk of sensors (parallel worker method)"""
        chunk_data = []
        
        # REALISTIC sensor ranges based on industrial manufacturing equipment
        sensor_ranges = {
            'temperature': (35, 75),      # Motor/bearing operating range: 35-75Â°C
            'vibration': (0.5, 8),        # ISO 10816: 0.5-8 mm/s normal, >8 alarm
            'pressure': (4, 8),           # Hydraulic systems: 4-8 bar normal
            'current': (5, 40),           # Motor current: 5-40A depending on load
            'voltage': (210, 230),        # Single phase supply: Â±10% of 220V
            'flow': (10, 80),             # Flow rate: 10-80 L/min typical
            'speed': (300, 2500),         # RPM varies by spindle type
            'torque': (10, 80)            # Torque load: 10-80 Nm typical
        }
        
        end_time = datetime.now()
        start_time = end_time - timedelta(days=14)
        local_id = start_id
        
        for sensor in sensor_chunk:
            sensor_type = sensor['sensor_type']
            min_val, max_val = sensor_ranges.get(sensor_type, (10, 100))
            
            for _ in range(100):  # Exactly 100 records per sensor
                timestamp = start_time + timedelta(seconds=random.randint(0, int((end_time-start_time).total_seconds())))
                
                # Normal distribution around midpoint (realistic)
                midpoint = (min_val + max_val) / 2
                sigma = (max_val - min_val) / 8
                measurement_value = random.gauss(midpoint, sigma)
                measurement_value = max(min_val * 0.95, min(max_val * 1.05, measurement_value))
                measurement_value = round(measurement_value, 4)
                
                # Most readings should be normal (98%), rare anomalies (2%)
                is_anomaly = random.random() < 0.02
                if is_anomaly:
                    measurement_value = round(random.uniform(max_val * 1.1, max_val * 1.3), 4)
                    anomaly_score = round(random.uniform(0.85, 1.0), 4)
                else:
                    anomaly_score = round(random.uniform(0, 0.2), 4)
                
                record = {
                    'sensor_data_id': local_id,
                    'sensor_id': sensor['sensor_id'],
                    'machine_id': sensor['machine_id'],
                    'line_id': sensor['line_id'],
                    'factory_id': sensor['factory_id'],
                    'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                    'measurement_value': measurement_value,
                    'measurement_unit': random.choice(['Â°C', 'mm/s', 'bar', 'A', 'V', 'L/min', 'rpm', 'Nm']),
                    'status': 'critical' if is_anomaly else ('warning' if random.random() < 0.05 else 'normal'),
                    'quality': 'bad' if is_anomaly else ('uncertain' if random.random() < 0.05 else 'good'),
                    'is_below_warning': measurement_value < min_val * 0.95,
                    'is_above_warning': measurement_value > max_val * 1.05,
                    'is_below_critical': measurement_value < min_val * 0.90,
                    'is_above_critical': measurement_value > max_val * 1.10,
                    'min_value_1min': round(measurement_value - random.uniform(0.5, 2), 4),
                    'max_value_1min': round(measurement_value + random.uniform(0.5, 2), 4),
                    'avg_value_1min': round(measurement_value + random.uniform(-0.5, 0.5), 4),
                    'std_dev_1min': round(random.uniform(0.05, 0.5), 4),
                    'is_anomaly': is_anomaly,
                    'anomaly_score': anomaly_score,
                    'data_source': random.choice(['IoT', 'Edge', 'Gateway']),
                    'protocol': random.choice(['OPC-UA', 'Modbus', 'MQTT']),
                    'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                chunk_data.append(record)
                local_id += 1
        
        return chunk_data
    
    def generate_sensor_data(self):
        """Generate sensor measurements with PARALLEL processing (159,900 records optimized)"""
        print("Generating sensor data with PARALLEL processing (159,900 records)...")
        
        if not self.parallel_enabled or len(self.sensors) < 100:
            return self._generate_sensor_data_sequential()
        
        # Parallel processing for large datasets
        chunk_size = max(50, len(self.sensors) // self.worker_count)  # At least 50 sensors per chunk
        sensor_chunks = [self.sensors[i:i + chunk_size] for i in range(0, len(self.sensors), chunk_size)]
        
        print(f"  ðŸš€ Processing {len(sensor_chunks)} sensor chunks with {self.worker_count} workers...")
        
        all_sensor_data = []
        start_id = 1
        
        with ThreadPoolExecutor(max_workers=self.worker_count) as executor:
            # Submit chunk processing tasks
            futures = {
                executor.submit(self._generate_sensor_data_chunk, chunk, chunk_id, start_id + chunk_id * chunk_size * 100): chunk_id 
                for chunk_id, chunk in enumerate(sensor_chunks)
            }
            
            # Collect results as they complete
            for future in as_completed(futures):
                chunk_id = futures[future]
                try:
                    chunk_data = future.result()
                    all_sensor_data.extend(chunk_data)
                    print(f"    âœ“ Sensor chunk {chunk_id + 1}/{len(sensor_chunks)} completed ({len(chunk_data)} records)")
                except Exception as e:
                    print(f"    âœ— Sensor chunk {chunk_id + 1} failed: {e}")
        
        # Store results
        with self.data_lock:
            self.data['sensor_data'].extend(all_sensor_data)
        
        print(f"âœ“ Generated {len(self.data['sensor_data'])} sensor data records via PARALLEL processing")
    
    def _generate_sensor_data_sequential(self):
        """Fallback sequential sensor data generation"""
        print("Generating sensor data (sequential fallback)...")
    
    def generate_production_lines(self):
        """Generate production lines (tied to factories)"""
        print("Generating production lines...")
        
        for factory_id in self.factories.keys():
            num_lines = random.randint(3, 5)
            for _ in range(num_lines):
                line = {
                    'line_id': self.get_next_id('LINE'),
                    'line_name': f"Line {len(self.production_lines)+1}",
                    'factory_id': factory_id,
                    'line_type': random.choice(['assembly', 'machining', 'testing', 'packaging']),
                    'status': 'active',
                    'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                self.production_lines.append(line)
        
        print(f"âœ“ Generated {len(self.production_lines)} production lines")
    
    def generate_machines(self):
        """Generate machines for each production line"""
        print("Generating machines...")
        
        for line in self.production_lines:
            num_machines = random.randint(5, 12)
            for _ in range(num_machines):
                machine = {
                    'machine_id': self.get_next_id('MACH'),
                    'machine_name': f"Machine {len(self.machines)+1}",
                    'line_id': line['line_id'],
                    'factory_id': line['factory_id'],
                    'machine_type': random.choice(['robot_arm', 'cnc_mill', 'conveyor', 'press']),
                    'status': 'active',
                    'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                self.machines.append(machine)
        
        print(f"âœ“ Generated {len(self.machines)} machines")
    
    def generate_sensors(self):
        """Generate sensors for each machine"""
        print("Generating sensors...")
        
        sensor_types = ['temperature', 'vibration', 'pressure', 'current', 'voltage', 'flow', 'speed', 'torque']
        
        for machine in self.machines:
            num_sensors = random.randint(3, 8)
            sensor_list = random.sample(sensor_types, min(num_sensors, len(sensor_types)))
            
            for sensor_type in sensor_list:
                sensor = {
                    'sensor_id': self.get_next_id('SEN'),
                    'sensor_name': f"{sensor_type.title()} Sensor",
                    'machine_id': machine['machine_id'],
                    'line_id': machine['line_id'],
                    'factory_id': machine['factory_id'],
                    'sensor_type': sensor_type,
                    'status': 'active',
                    'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                self.sensors.append(sensor)
        
        print(f"âœ“ Generated {len(self.sensors)} sensors")
    
    def generate_sensor_data(self):
        """Generate sensor measurements aligned with IoT daemon output (159,900 records)"""
        print("Generating sensor data (aligned with IoT daemon: 159,900 records)...")
        
        # REALISTIC sensor ranges based on industrial manufacturing equipment
        # These are actual ranges from ISO/IEC standards for manufacturing
        sensor_ranges = {
            'temperature': (35, 75),      # Motor/bearing operating range: 35-75Â°C
            'vibration': (0.5, 8),        # ISO 10816: 0.5-8 mm/s normal, >8 alarm
            'pressure': (4, 8),           # Hydraulic systems: 4-8 bar normal
            'current': (5, 40),           # Motor current: 5-40A depending on load
            'voltage': (210, 230),        # Single phase supply: Â±10% of 220V
            'flow': (10, 80),             # Flow rate: 10-80 L/min typical
            'speed': (300, 2500),         # RPM varies by spindle type
            'torque': (10, 80)            # Torque load: 10-80 Nm typical
        }
        
        end_time = datetime.now()
        start_time = end_time - timedelta(days=14)
        sensor_data_id = 1
        
        # Generate exactly 100 records per sensor to match IoT daemon (1599 sensors * 100 = 159,900)
        for sensor in self.sensors:
            sensor_type = sensor['sensor_type']
            min_val, max_val = sensor_ranges.get(sensor_type, (10, 100))
            
            for _ in range(100):  # Exactly 100 records per sensor for 14-day period
                timestamp = start_time + timedelta(seconds=random.randint(0, int((end_time-start_time).total_seconds())))
                
                # Normal distribution around midpoint (realistic)
                midpoint = (min_val + max_val) / 2
                sigma = (max_val - min_val) / 8  # Tighter distribution, 98% within range
                measurement_value = random.gauss(midpoint, sigma)
                # Clamp strictly to range
                measurement_value = max(min_val * 0.95, min(max_val * 1.05, measurement_value))
                measurement_value = round(measurement_value, 4)
                
                # Most readings should be normal (80%), rare anomalies (20%)
                is_anomaly = random.random() < 0.02  # Only 2% true anomalies
                if is_anomaly:
                    # Force out-of-range anomaly
                    measurement_value = round(random.uniform(max_val * 1.1, max_val * 1.3), 4)
                    anomaly_score = round(random.uniform(0.85, 1.0), 4)
                else:
                    anomaly_score = round(random.uniform(0, 0.2), 4)
                
                record = {
                    'sensor_data_id': sensor_data_id,
                    'sensor_id': sensor['sensor_id'],
                    'machine_id': sensor['machine_id'],
                    'line_id': sensor['line_id'],
                    'factory_id': sensor['factory_id'],
                    'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                    'measurement_value': measurement_value,
                    'measurement_unit': random.choice(['Â°C', 'mm/s', 'bar', 'A', 'V', 'L/min', 'rpm', 'Nm']),
                    'status': 'critical' if is_anomaly else ('warning' if random.random() < 0.05 else 'normal'),
                    'quality': 'bad' if is_anomaly else ('uncertain' if random.random() < 0.05 else 'good'),
                    'is_below_warning': measurement_value < min_val * 0.95,
                    'is_above_warning': measurement_value > max_val * 1.05,
                    'is_below_critical': measurement_value < min_val * 0.90,
                    'is_above_critical': measurement_value > max_val * 1.10,
                    'min_value_1min': round(measurement_value - random.uniform(0.5, 2), 4),
                    'max_value_1min': round(measurement_value + random.uniform(0.5, 2), 4),
                    'avg_value_1min': round(measurement_value + random.uniform(-0.5, 0.5), 4),
                    'std_dev_1min': round(random.uniform(0.05, 0.5), 4),
                    'is_anomaly': is_anomaly,
                    'anomaly_score': anomaly_score,
                    'data_source': random.choice(['IoT', 'Edge', 'Gateway']),
                    'protocol': random.choice(['OPC-UA', 'Modbus', 'MQTT']),
                    'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                self.data['sensor_data'].append(record)
                sensor_data_id += 1
        
        print(f"âœ“ Generated {len(self.data['sensor_data'])} sensor data records")
    
    def _generate_scada_data_chunk(self, machine_chunk: List[dict], chunk_id: int, start_id: int, machine_faults_by_id: dict) -> List[dict]:
        """Generate SCADA data for a chunk of machines (parallel worker method)"""
        chunk_data = []
        
        end_time = datetime.now()
        start_time = end_time - timedelta(days=14)
        local_id = start_id
        
        # Generate exactly 336 records per machine to match SCADA daemon
        for machine in machine_chunk:
            machine_faults = machine_faults_by_id.get(machine['machine_id'], [])
            
            for _ in range(336):  # Exactly 336 records per machine for 14-day period
                timestamp = start_time + timedelta(seconds=random.randint(0, int((end_time-start_time).total_seconds())))
                actual_cycle = round(random.uniform(15, 45), 2)
                
                # REALISTIC machine state distribution
                machine_state = random.choices(
                    ['running', 'idle', 'setup', 'stopped', 'maintenance', 'fault'],
                    weights=[0.82, 0.10, 0.04, 0.01, 0.02, 0.01]
                )[0]
                has_fault = machine_state in ['fault', 'maintenance']
                
                # Realistic availability: 95-99%
                if machine_state == 'running':
                    availability = round(random.gauss(97, 1.5), 2)
                    availability = max(95, min(99, availability))
                else:
                    availability = round(random.uniform(70, 95), 2)
                
                # Smart fault code/description linking
                fault_code = None
                fault_description = None
                
                if has_fault:
                    if machine_faults and random.random() < 0.70:
                        # Try to link to a nearby fault record
                        selected_fault = random.choice(machine_faults)
                        fault_code = selected_fault.get('fault_code', f"ERR-{random.randint(100, 999)}")
                        fault_description = selected_fault.get('fault_description', 'System fault detected')
                    else:
                        # Generate new fault code
                        fault_code = f"ERR-{random.randint(100, 999)}"
                        fault_description = random.choice([
                            'Bearing temperature high',
                            'Spindle misalignment detected',
                            'Lubrication pressure low',
                            'Motor overcurrent condition',
                            'Tool wear threshold exceeded',
                            'Conveyor jam detected'
                        ])
                
                # Calculate realistic OEE
                perf_pct = round(random.gauss(94, 2), 2)
                perf_pct = max(90, min(98, perf_pct))
                qual_pct = round(random.gauss(97, 1.5), 2)
                qual_pct = max(95, min(99, qual_pct))
                calculated_oee = round((availability * perf_pct * qual_pct) / 10000, 2)
                
                record = {
                    'scada_id': local_id,
                    'machine_id': machine['machine_id'],
                    'line_id': machine['line_id'],
                    'factory_id': machine['factory_id'],
                    'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                    'machine_state': machine_state,
                    'operation_mode': random.choice(['auto', 'manual', 'test']),
                    'fault_code': fault_code,
                    'fault_description': fault_description,
                    'parts_produced_cumulative': random.randint(10000, 100000),
                    'parts_produced_shift': random.randint(100, 1000),
                    'parts_rejected_shift': random.randint(0, 50),
                    'target_cycle_time_seconds': 30,
                    'actual_cycle_time_seconds': actual_cycle,
                    'availability_percentage': availability,
                    'performance_percentage': perf_pct,
                    'quality_percentage': qual_pct,
                    'oee_percentage': calculated_oee,
                    'spindle_speed_rpm': random.randint(500, 5000),
                    'feed_rate_mm_min': round(random.uniform(50, 500), 2),
                    'tool_number': random.randint(1, 20),
                    'program_number': f"PROG-{random.randint(1000, 9999)}",
                    'power_consumption_kw': round(random.uniform(5, 50), 2),
                    'energy_consumed_kwh': round(random.uniform(10, 500), 4),
                    'temperature_setpoint_c': round(random.uniform(20, 80), 2),
                    'temperature_actual_c': round(random.uniform(20, 85), 2),
                    'pressure_setpoint_bar': round(random.uniform(5, 10), 2),
                    'pressure_actual_bar': round(random.uniform(5, 11), 2),
                    'downtime_seconds_shift': random.randint(0, 3600),
                    'last_fault_timestamp': (timestamp - timedelta(hours=random.randint(1, 48))).strftime('%Y-%m-%d %H:%M:%S') if (has_fault or random.random() < 0.50) else None,
                    'uptime_seconds_shift': random.randint(3600, 28800),
                    'active_alarms': random.randint(0, 5),
                    'alarm_codes': ','.join([f"ALM-{random.randint(100, 999)}" for _ in range(random.randint(1, 4))]) if random.random() < 0.75 else None,
                    'warning_codes': ','.join([f"WRN-{random.randint(100, 999)}" for _ in range(random.randint(1, 3))]) if random.random() < 0.70 else None,
                    'shift_id': random.choice([s['shift_id'] for s in self.shifts]) if self.shifts else f"SHF-{random.randint(1, 3):03d}",
                    'operator_id': random.choice(list(self.employees.keys())),
                    'data_source': 'PLC',
                    'data_quality': random.choice(['good', 'uncertain', 'bad']),
                    'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                chunk_data.append(record)
                local_id += 1
        
        return chunk_data
    
    def generate_scada_data(self):
        """Generate SCADA machine data with PARALLEL processing (70,896 records optimized)"""
        print("Generating SCADA data with PARALLEL processing (70,896 records)...")
        
        # Build machine-indexed fault list for fast lookup
        machine_faults_by_id = {}
        for fault in self.data.get('machine_faults', []):
            mid = fault['machine_id']
            if mid not in machine_faults_by_id:
                machine_faults_by_id[mid] = []
            machine_faults_by_id[mid].append(fault)
        
        if not self.parallel_enabled or len(self.machines) < 20:
            return self._generate_scada_data_sequential(machine_faults_by_id)
        
        # Parallel processing for large datasets
        chunk_size = max(10, len(self.machines) // self.worker_count)  # At least 10 machines per chunk
        machine_chunks = [self.machines[i:i + chunk_size] for i in range(0, len(self.machines), chunk_size)]
        
        print(f"  ðŸš€ Processing {len(machine_chunks)} machine chunks with {self.worker_count} workers...")
        
        all_scada_data = []
        start_id = 1
        
        with ThreadPoolExecutor(max_workers=self.worker_count) as executor:
            # Submit chunk processing tasks
            futures = {
                executor.submit(self._generate_scada_data_chunk, chunk, chunk_id, start_id + chunk_id * chunk_size * 336, machine_faults_by_id): chunk_id 
                for chunk_id, chunk in enumerate(machine_chunks)
            }
            
            # Collect results as they complete
            for future in as_completed(futures):
                chunk_id = futures[future]
                try:
                    chunk_data = future.result()
                    all_scada_data.extend(chunk_data)
                    print(f"    âœ“ SCADA chunk {chunk_id + 1}/{len(machine_chunks)} completed ({len(chunk_data)} records)")
                except Exception as e:
                    print(f"    âœ— SCADA chunk {chunk_id + 1} failed: {e}")
        
        # Store results
        with self.data_lock:
            self.data['scada_machine_data'].extend(all_scada_data)
        
        print(f"âœ“ Generated {len(self.data['scada_machine_data'])} SCADA records via PARALLEL processing")
    
    def _generate_scada_data_sequential(self, machine_faults_by_id: dict):
        """Fallback sequential SCADA data generation"""
        print("Generating SCADA data (sequential fallback)...")
    
    def generate_scada_data(self):
        """Generate SCADA machine data aligned with daemon output (70,896 records)"""
        print("Generating SCADA data (aligned with SCADA daemon: 70,896 records)...")
        
        end_time = datetime.now()
        start_time = end_time - timedelta(days=14)
        scada_id = 1  # Track BIGSERIAL primary key
        
        # Build machine-indexed fault list for fast lookup
        machine_faults_by_id = {}
        for fault in self.data.get('machine_faults', []):
            mid = fault['machine_id']
            if mid not in machine_faults_by_id:
                machine_faults_by_id[mid] = []
            machine_faults_by_id[mid].append(fault)
        
        # Generate exactly 336 records per machine to match SCADA daemon (211 machines * 336 = 70,896)
        for machine in self.machines:
            machine_faults = machine_faults_by_id.get(machine['machine_id'], [])
            
            # Exactly 336 records per machine for 14-day period (24 records per day)
            for _ in range(336):
                timestamp = start_time + timedelta(seconds=random.randint(0, int((end_time-start_time).total_seconds())))
                actual_cycle = round(random.uniform(15, 45), 2)
                
                # REALISTIC machine state distribution for good manufacturing
                # running: 82%, idle: 10%, setup: 4%, stopped: 1%, maintenance: 2%, fault: 1%
                machine_state = random.choices(
                    ['running', 'idle', 'setup', 'stopped', 'maintenance', 'fault'],
                    weights=[0.82, 0.10, 0.04, 0.01, 0.02, 0.01]
                )[0]
                has_fault = machine_state in ['fault', 'maintenance']
                
                # Realistic availability: 95-99% for good manufacturing
                if machine_state == 'running':
                    availability = round(random.gauss(97, 1.5), 2)
                    availability = max(95, min(99, availability))
                else:
                    availability = round(random.uniform(70, 95), 2)
                
                # Smart fault code/description linking
                fault_code = None
                fault_description = None
                
                # Strategy: Always populate fault code when state is 'fault' or 'maintenance'
                # Prefer linking to existing machine faults (70% if available), else generate
                if has_fault:
                    if machine_faults and random.random() < 0.70:
                        # Try to link to a nearby fault record
                        matching_faults = []
                        for fault in machine_faults:
                            fault_start = datetime.strptime(fault['fault_start_time'], '%Y-%m-%d %H:%M:%S')
                            fault_end_str = fault['fault_end_time']
                            fault_end = datetime.strptime(fault_end_str, '%Y-%m-%d %H:%M:%S') if fault_end_str else fault_start + timedelta(hours=24)
                            # Liberal window: Â±4 hours around fault period
                            if fault_start - timedelta(hours=4) <= timestamp <= fault_end + timedelta(hours=4):
                                matching_faults.append(fault)
                        
                        # If found a matching fault, use it
                        if matching_faults:
                            selected_fault = random.choice(matching_faults)
                            fault_code = selected_fault['fault_code']
                            fault_description = selected_fault['fault_description']
                        else:
                            # No matching fault in time window, pick a random one
                            selected_fault = random.choice(machine_faults)
                            fault_code = selected_fault['fault_code']
                            fault_description = selected_fault['fault_description']
                    else:
                        # Generate a new fault code (30% when faults exist, or when no faults at all)
                        fault_code = f"ERR-{random.randint(100, 999)}"
                        fault_description = random.choice([
                            'Bearing temperature high',
                            'Spindle misalignment detected',
                            'Lubrication pressure low',
                            'Motor overcurrent condition',
                            'Tool wear threshold exceeded',
                            'Conveyor jam detected'
                        ])
                
                # Calculate realistic OEE for good manufacturing (75-85%)
                # Availability: 95-99%, Performance: 90-98%, Quality: 95-99%
                perf_pct = round(random.gauss(94, 2), 2)
                perf_pct = max(90, min(98, perf_pct))
                qual_pct = round(random.gauss(97, 1.5), 2)
                qual_pct = max(95, min(99, qual_pct))
                calculated_oee = round((availability * perf_pct * qual_pct) / 10000, 2)
                
                record = {
                    'scada_id': scada_id,  # BIGSERIAL primary key
                    'machine_id': machine['machine_id'],
                    'line_id': machine['line_id'],
                    'factory_id': machine['factory_id'],
                    'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                    'machine_state': machine_state,
                    'operation_mode': random.choice(['auto', 'manual', 'test']),
                    'fault_code': fault_code,
                    'fault_description': fault_description,
                    'parts_produced_cumulative': random.randint(10000, 100000),
                    'parts_produced_shift': random.randint(100, 1000),
                    'parts_rejected_shift': random.randint(0, 50),
                    'target_cycle_time_seconds': 30,
                    'actual_cycle_time_seconds': actual_cycle,
                    'availability_percentage': availability,
                    'performance_percentage': perf_pct,
                    'quality_percentage': qual_pct,
                    'oee_percentage': calculated_oee,
                    'spindle_speed_rpm': random.randint(500, 5000),
                    'feed_rate_mm_min': round(random.uniform(50, 500), 2),
                    'tool_number': random.randint(1, 20),
                    'program_number': f"PROG-{random.randint(1000, 9999)}",
                    'power_consumption_kw': round(random.uniform(5, 50), 2),
                    'energy_consumed_kwh': round(random.uniform(10, 500), 4),
                    'temperature_setpoint_c': round(random.uniform(20, 80), 2),
                    'temperature_actual_c': round(random.uniform(20, 85), 2),
                    'pressure_setpoint_bar': round(random.uniform(5, 10), 2),
                    'pressure_actual_bar': round(random.uniform(5, 11), 2),
                    'downtime_seconds_shift': random.randint(0, 3600),
                    'last_fault_timestamp': (timestamp - timedelta(hours=random.randint(1, 48))).strftime('%Y-%m-%d %H:%M:%S') if (has_fault or random.random() < 0.50) else None,
                    'uptime_seconds_shift': random.randint(3600, 28800),
                    'active_alarms': random.randint(0, 5),
                    'alarm_codes': ','.join([f"ALM-{random.randint(100, 999)}" for _ in range(random.randint(1, 4))]) if random.random() < 0.75 else None,
                    'warning_codes': ','.join([f"WRN-{random.randint(100, 999)}" for _ in range(random.randint(1, 3))]) if random.random() < 0.70 else None,
                    'shift_id': random.choice([s['shift_id'] for s in self.shifts]),
                    'operator_id': random.choice(list(self.employees.keys())),
                    'data_source': 'PLC',
                    'data_quality': random.choice(['good', 'uncertain', 'bad']),
                    'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                self.data['scada_machine_data'].append(record)
                scada_id += 1
        
        print(f"âœ“ Generated {len(self.data['scada_machine_data'])} SCADA records")
    
    def _generate_production_runs_chunk(self, machines_chunk: List[dict], chunk_id: int, start_id: int) -> List[dict]:
        """Generate production runs for a chunk of machines (parallel worker method)"""
        chunk_data = []
        local_id = start_id
        product_list = list(self.products.keys())
        
        # Generate runs over 180-day period
        end_time = datetime.now()
        start_time = end_time - timedelta(days=180)
        
        for machine in machines_chunk:
            # Generate 8-12 production runs per machine over 180 days
            runs_for_machine = random.randint(8, 12)
            
            for run_num in range(runs_for_machine):
                # Random run timing within the 180-day window
                run_start = start_time + timedelta(days=random.randint(0, 179))
                run_duration = timedelta(hours=random.randint(2, 24))
                run_end = run_start + run_duration
                actual_duration_minutes = int((run_end - run_start).total_seconds() / 60)
                
                selected_product_id = random.choice(product_list)
                customer_id = random.choice([c['customer_id'] for c in self.customers])
                
                # Realistic yield calculation
                defect_rate = round(random.gauss(0.025, 0.01), 4)  # 2.5% avg defect rate
                defect_rate = max(0.001, min(0.08, defect_rate))  # 0.1-8% range
                
                target_quantity = random.randint(100, 1000)
                
                # REALISTIC quality: 70-80% Grade A (zero-defect focus)
                quality_grade = random.choices(
                    ['A', 'B', 'C'],
                    weights=[0.75, 0.20, 0.05]
                )[0]
                
                # First pass yield: 90-98% (high, good manufacturing)
                first_pass_yield = round(random.gauss(95, 1.5), 2)
                first_pass_yield = max(90, min(99, first_pass_yield))
                
                # Defect rate: 100-500 PPM (good manufacturing)
                if quality_grade == 'A':
                    defect_rate = random.randint(100, 250)
                elif quality_grade == 'B':
                    defect_rate = random.randint(250, 400)
                else:
                    defect_rate = random.randint(400, 600)
                
                # OEE calculations (realistic manufacturing)
                av_pct = round(random.gauss(87, 4), 2)  # Availability: 82-92% avg
                perf_pct = round(random.gauss(85, 3), 2)  # Performance: 80-90% avg
                qual_pct = round(random.gauss(96.5, 1), 2)  # Quality: 95-98% avg
                oee_pct = round((av_pct * perf_pct * qual_pct) / 10000, 2)  # OEE = A*P*Q/100
                
                # Previous product for changeover analysis
                previous_product_id = random.choice(product_list) if run_num > 0 else selected_product_id
                
                run = {
                    'run_id': self.get_next_id('RUN'),
                    'line_id': machine['line_id'],  # From machines table which has line_id
                    'factory_id': machine['factory_id'],
                    'product_id': selected_product_id,
                    'run_number': random.randint(1000, 9999),
                    'batch_number': f"BATCH-{random.randint(100000, 999999)}",
                    'work_order_number': f"WO-{random.randint(100000, 999999)}",
                    'customer_id': customer_id,
                    'run_start_time': run_start.strftime('%Y-%m-%d %H:%M:%S'),
                    'run_end_time': run_end.strftime('%Y-%m-%d %H:%M:%S'),
                    'planned_duration_minutes': random.randint(120, 720),
                    'actual_duration_minutes': actual_duration_minutes,
                    'target_quantity': target_quantity,
                    'actual_quantity': random.randint(int(target_quantity * 0.95), int(target_quantity * 0.99)),
                    'rejected_quantity': random.randint(0, int(target_quantity * 0.01)),
                    'scrapped_quantity': random.randint(0, int(target_quantity * 0.005)),
                    'rework_quantity': random.randint(0, int(target_quantity * 0.01)),
                    'first_pass_yield_percentage': first_pass_yield,
                    'defect_rate_ppm': defect_rate,
                    'quality_grade': quality_grade,
                    'oee_percentage': oee_pct,
                    'availability_percentage': av_pct,
                    'performance_percentage': perf_pct,
                    'quality_percentage': qual_pct,
                    'previous_product_id': previous_product_id,
                    'changeover_time_minutes': random.randint(5, 60),
                    'shift_id': random.choice([s['shift_id'] for s in self.shifts]) if self.shifts else f"SHF-{random.randint(1, 3):03d}",
                    'supervisor_id': random.choice(list(self.employees.keys())),
                    'status': random.choices(['scheduled', 'in_progress', 'completed', 'aborted'], weights=[0.1, 0.15, 0.7, 0.05])[0],
                    'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'updated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                chunk_data.append(run)
                local_id += 1
        
        return chunk_data
    
    def generate_production_runs(self):
        """Generate production run data with PARALLEL processing"""
        print("Generating production run data with PARALLEL processing...")
        
        # Generate production runs directly from machines (not from production_orders)
        if not self.machines:
            print("No machines found. Skipping production runs.")
            return
        
        if not self.parallel_enabled or len(self.machines) < 20:
            return self._generate_production_runs_sequential(self.machines)
        
        # Parallel processing for large datasets
        chunk_size = max(5, len(self.machines) // self.worker_count)  # At least 5 machines per chunk
        machine_chunks = [self.machines[i:i + chunk_size] for i in range(0, len(self.machines), chunk_size)]
        
        print(f"  ðŸš€ Processing {len(machine_chunks)} machine chunks with {self.worker_count} workers...")
        
        all_production_runs = []
        start_id = 1
        
        with ThreadPoolExecutor(max_workers=self.worker_count) as executor:
            # Submit chunk processing tasks
            futures = {
                executor.submit(self._generate_production_runs_chunk, chunk, chunk_id, start_id + chunk_id * chunk_size * 10): chunk_id  # Avg 10 runs per machine
                for chunk_id, chunk in enumerate(machine_chunks)
            }
            
            # Collect results as they complete
            for future in as_completed(futures):
                chunk_id = futures[future]
                try:
                    chunk_data = future.result()
                    all_production_runs.extend(chunk_data)
                    print(f"    âœ“ Production runs chunk {chunk_id + 1}/{len(machine_chunks)} completed ({len(chunk_data)} records)")
                except Exception as e:
                    print(f"    âœ— Production runs chunk {chunk_id + 1} failed: {e}")
        
        # Store results
        with self.data_lock:
            self.data['production_runs'].extend(all_production_runs)
        
        print(f"âœ“ Generated {len(self.data['production_runs'])} production run records via PARALLEL processing")
    
    def _generate_production_runs_sequential(self, machines: List[dict]):
        """Fallback sequential production runs generation"""
        print("Generating production runs (sequential fallback)...")
        """Generate production runs over 180-day period directly from machines"""
        print("Generating production runs (180-day period)...")
        
        product_list = list(self.products.keys())
        
        # Align with MES: 180-day period
        end_time = datetime.now()
        start_time = end_time - timedelta(days=180)
        
        for machine in machines:
            # Scale runs over 180 days: ~2-4 runs per machine per week = 26-52 runs per machine
            num_runs = random.randint(26, 52)
            
            for idx in range(num_runs):
                # Distribute runs over 180-day period
                run_start = start_time + timedelta(days=random.randint(0, 179))
                run_duration = timedelta(hours=random.randint(2, 24))
                run_end = run_start + run_duration
                actual_duration_minutes = int((run_end - run_start).total_seconds() / 60)
                
                selected_product_id = random.choice(product_list)
                previous_product_id = random.choice(product_list) if idx > 0 else selected_product_id
                customer_id = random.choice([c['customer_id'] for c in self.customers])
                
                # REALISTIC quality: 70-80% Grade A (zero-defect focus)
                quality_grade = random.choices(
                    ['A', 'B', 'C'],
                    weights=[0.75, 0.20, 0.05]
                )[0]
                
                # First pass yield: 90-98% (high, good manufacturing)
                first_pass_yield = round(random.gauss(95, 1.5), 2)
                first_pass_yield = max(90, min(99, first_pass_yield))
                
                # Defect rate: 100-500 PPM (good manufacturing)
                if quality_grade == 'A':
                    defect_rate = round(random.gauss(200, 80), 0)
                elif quality_grade == 'B':
                    defect_rate = round(random.gauss(800, 200), 0)
                else:  # C grade
                    defect_rate = round(random.gauss(2000, 400), 0)
                defect_rate = max(0, min(5000, defect_rate))
                
                # Realistic OEE 70-85% (from component multiplication)
                av_pct = round(random.gauss(96, 2), 2)
                av_pct = max(90, min(99, av_pct))
                perf_pct = round(random.gauss(92, 2), 2)
                perf_pct = max(85, min(98, perf_pct))
                qual_pct = round(random.gauss(96, 1.5), 2)
                qual_pct = max(90, min(99, qual_pct))
                oee_pct = round((av_pct * perf_pct * qual_pct) / 10000, 2)
                target_quantity = random.randint(100, 1000)
                run = {
                    'run_id': self.get_next_id('RUN'),
                    'line_id': machine['line_id'],  # From machines table which has line_id
                    'factory_id': machine['factory_id'],
                    'product_id': selected_product_id,
                    'run_number': random.randint(1000, 9999),
                    'batch_number': f"BATCH-{random.randint(100000, 999999)}",
                    'work_order_number': f"WO-{random.randint(100000, 999999)}",
                    'customer_id': customer_id,
                    'run_start_time': run_start.strftime('%Y-%m-%d %H:%M:%S'),
                    'run_end_time': run_end.strftime('%Y-%m-%d %H:%M:%S'),
                    'planned_duration_minutes': random.randint(120, 720),
                    'actual_duration_minutes': actual_duration_minutes,
                    'target_quantity': target_quantity,
                    'actual_quantity': random.randint(int(target_quantity * 0.95), int(target_quantity * 0.99)),
                    'rejected_quantity': random.randint(0, int(target_quantity * 0.01)),
                    'scrapped_quantity': random.randint(0, int(target_quantity * 0.005)),
                    'rework_quantity': random.randint(0, int(target_quantity * 0.01)),
                    'first_pass_yield_percentage': first_pass_yield,
                    'defect_rate_ppm': defect_rate,
                    'quality_grade': quality_grade,
                    'oee_percentage': oee_pct,
                    'availability_percentage': av_pct,
                    'performance_percentage': perf_pct,
                    'quality_percentage': qual_pct,
                    'previous_product_id': previous_product_id,
                    'changeover_time_minutes': random.randint(5, 60),
                    'shift_id': random.choice([s['shift_id'] for s in self.shifts]),
                    'supervisor_id': random.choice(list(self.employees.keys())),
                    'status': random.choice(['completed', 'in_progress', 'paused', 'aborted']),
                    'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'updated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                self.data['production_runs'].append(run)
        
        print(f"âœ“ Generated {len(self.data['production_runs'])} production runs")
    
    def generate_machine_faults(self):
        """Generate machine faults over 180-day period to align with MES"""
        print("Generating machine faults (180-day period)...")
        
        employee_list = list(self.employees.keys())
        fault_id = 1
        
        # Align with MES: 180-day period
        end_time = datetime.now()
        start_time = end_time - timedelta(days=180)
        
        for machine in self.machines:
            # REALISTIC: Over 180 days, 60% of machines experience faults
            # Those that do have 2-8 faults over 6 months
            if random.random() < 0.60:
                num_faults = random.randint(2, 8)
            else:
                num_faults = 0
            
            for _ in range(num_faults):
                # Distribute faults over 180-day period
                fault_start_time = start_time + timedelta(days=random.randint(0, 179))
                
                # REALISTIC fault duration follows exponential distribution
                # Most faults are short (< 1 hour), some longer
                # 60% < 15 min, 25% 15min-2hr, 10% 2-8hr, 5% > 8hr
                rand_val = random.random()
                if rand_val < 0.60:
                    duration_hours = random.uniform(0.05, 0.25)  # 3-15 minutes
                elif rand_val < 0.85:
                    duration_hours = random.uniform(0.25, 2)     # 15 min - 2 hours
                elif rand_val < 0.95:
                    duration_hours = random.uniform(2, 8)        # 2-8 hours
                else:
                    duration_hours = random.uniform(8, 24)       # 8-24 hours (rare)
                
                end_time = start_time + timedelta(hours=duration_hours)
                # High probability to close faults (most get resolved)
                fault_status = random.choices(
                    ['closed', 'resolved', 'in_progress', 'acknowledged'],
                    weights=[0.70, 0.20, 0.07, 0.03]
                )[0]
                
                has_end_time = fault_status in ['resolved', 'closed'] or random.random() < 0.95
                has_resolved_by = fault_status in ['resolved', 'closed'] or random.random() < 0.85
                fault_duration_seconds = int((end_time - start_time).total_seconds()) if has_end_time else None
                
                # REALISTIC fault types by frequency
                fault_categories = {
                    'mechanical': 0.40,  # Most common (bearing, alignment)
                    'electrical': 0.25,  # Second most common
                    'hydraulic': 0.15,
                    'quality': 0.10,
                    'control': 0.07,
                    'pneumatic': 0.03
                }
                fault_category = random.choices(
                    list(fault_categories.keys()),
                    weights=list(fault_categories.values())
                )[0]
                
                # Severity matches category
                if fault_category == 'mechanical':
                    severity_dist = {'major': 0.50, 'critical': 0.30, 'minor': 0.20}
                elif fault_category == 'electrical':
                    severity_dist = {'critical': 0.60, 'major': 0.35, 'minor': 0.05}
                else:
                    severity_dist = {'major': 0.50, 'minor': 0.40, 'warning': 0.10}
                
                fault_severity = random.choices(
                    list(severity_dist.keys()),
                    weights=list(severity_dist.values())
                )[0]
                
                fault = {
                    'fault_id': fault_id,
                    'machine_id': machine['machine_id'],
                    'line_id': machine['line_id'],
                    'factory_id': machine['factory_id'],
                    'fault_code': f"ERR-{random.randint(100, 999)}",
                    'fault_category': fault_category,
                    'fault_severity': fault_severity,
                    'fault_description': f"{fault_category.capitalize()} fault in {machine['machine_type']}",
                    'fault_start_time': start_time.strftime('%Y-%m-%d %H:%M:%S'),
                    'fault_end_time': end_time.strftime('%Y-%m-%d %H:%M:%S') if has_end_time else None,
                    'fault_duration_seconds': fault_duration_seconds,
                    'production_loss_units': int(100 * duration_hours) if fault_severity == 'critical' else int(50 * duration_hours),
                    'downtime_minutes': int(duration_hours * 60),
                    'estimated_cost_usd': round(random.uniform(500, 5000) if fault_severity == 'critical' else random.uniform(100, 2000), 2),
                    'root_cause_category': random.choice(['bearing_failure', 'overheating', 'tool_wear', 'misalignment', 'power_issue', 'sensor_fault']),
                    'root_cause_description': 'Analysis completed',
                    'contributing_sensors': ','.join([s['sensor_id'] for s in random.sample(self.sensors, min(2, len(self.sensors)))]),
                    'resolution_action': random.choice(['Maintenance scheduled', 'Repaired on-site', 'Part replacement']),
                    'maintenance_ticket_id': f"MNT-{random.randint(100000, 999999)}",
                    'resolved_by': random.choice(employee_list) if has_resolved_by else None,
                    'detection_method': random.choices(
                        ['sensor_threshold', 'predictive_model', 'operator_report', 'automatic'],
                        weights=[0.40, 0.35, 0.15, 0.10]
                    )[0],
                    'predicted_in_advance': fault_severity in ['critical', 'major'],  # Predictability by severity
                    'advance_warning_hours': round(random.uniform(4, 48), 2) if fault_severity in ['critical', 'major'] else None,
                    'status': fault_status,
                    'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'updated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                self.data['machine_faults'].append(fault)
                fault_id += 1
        
        print(f"âœ“ Generated {len(self.data['machine_faults'])} machine faults")
    
    def generate_sensor_health(self):
        """Generate sensor health metrics"""
        print("Generating sensor health metrics...")
        
        end_time = datetime.now()
        start_time = end_time - timedelta(days=14)
        health_id = 1  # Track BIGSERIAL primary key
        
        for sensor in self.sensors:
            # ~100 records per sensor
            for _ in range(100):
                timestamp = start_time + timedelta(seconds=random.randint(0, int((end_time-start_time).total_seconds())))
                
                record = {
                    'health_id': health_id,  # BIGSERIAL primary key
                    'sensor_id': sensor['sensor_id'],
                    'machine_id': sensor['machine_id'],
                    'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                    'health_score': round(random.uniform(50, 100), 2),
                    'drift_percentage': round(random.uniform(-5, 5), 4),
                    'noise_level': round(random.uniform(0.1, 10), 4),
                    'days_since_calibration': random.randint(1, 365),
                    'is_calibration_due': random.random() < 0.1,
                    'calibration_drift_detected': random.random() < 0.05,
                    'packet_loss_percentage': round(random.uniform(0, 5), 2),
                    'average_latency_ms': round(random.uniform(10, 500), 2),
                    'last_communication': timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                    'communication_failures_24h': random.randint(0, 10),
                    'battery_percentage': round(random.uniform(20, 100), 2),
                    'is_low_battery': random.random() < 0.1,
                    'stuck_value_detected': random.random() < 0.02,
                    'erratic_readings_detected': random.random() < 0.05,
                    'out_of_range_readings_24h': random.randint(0, 20),
                    'overall_status': random.choice(['healthy', 'degraded', 'critical', 'failed']),
                    'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                self.data['sensor_health'].append(record)
                health_id += 1
        
        print(f"âœ“ Generated {len(self.data['sensor_health'])} sensor health records")
    
    def generate_maintenance_events(self):
        """Generate maintenance events - realistic distribution"""
        print("Generating maintenance events...")
        
        employee_list = list(self.employees.keys())
        
        # Build lookup of faults by machine for linking
        faults_by_machine = {}
        for fault in self.data['machine_faults']:
            machine_id = fault['machine_id']
            if machine_id not in faults_by_machine:
                faults_by_machine[machine_id] = []
            faults_by_machine[machine_id].append(fault['fault_id'])
        
        for machine in self.machines:
            # REALISTIC: 4-6 maintenance events per machine per month = 24-36 events per machine over 180 days
            num_events = random.randint(24, 36)
            
            # Align with MES: 180-day period 
            end_time = datetime.now()
            start_time = end_time - timedelta(days=180)
            
            for idx in range(num_events):
                # Distribute events over 180-day period
                event_start = start_time + timedelta(days=random.randint(0, 179))
                
                # REALISTIC maintenance type distribution
                # preventive: 65%, corrective: 20%, inspection: 10%, breakdown: 3%, replacement: 2%
                maintenance_type = random.choices(
                    ['preventive', 'corrective', 'inspection', 'breakdown', 'replacement'],
                    weights=[0.65, 0.20, 0.10, 0.03, 0.02]
                )[0]
                
                # Duration matches type
                if maintenance_type == 'preventive':
                    event_duration = timedelta(hours=round(random.gauss(2, 0.5), 1))
                    parts_cost = round(random.gauss(200, 80), 2)
                    labor_hours = round(random.gauss(2, 0.5), 2)
                elif maintenance_type == 'breakdown':
                    event_duration = timedelta(hours=round(random.gauss(6, 1.5), 1))
                    parts_cost = round(random.gauss(1500, 500), 2)
                    labor_hours = round(random.gauss(8, 2), 2)
                elif maintenance_type == 'corrective':
                    event_duration = timedelta(hours=round(random.gauss(3, 0.8), 1))
                    parts_cost = round(random.gauss(600, 200), 2)
                    labor_hours = round(random.gauss(3, 0.8), 2)
                elif maintenance_type == 'replacement':
                    event_duration = timedelta(hours=round(random.gauss(4, 1), 1))
                    parts_cost = round(random.gauss(2000, 600), 2)
                    labor_hours = round(random.gauss(4, 1), 2)
                else:  # inspection
                    event_duration = timedelta(hours=round(random.gauss(1.5, 0.4), 1))
                    parts_cost = round(random.gauss(100, 40), 2)
                    labor_hours = round(random.gauss(1.5, 0.4), 2)
                
                event_end = event_start + event_duration
                labor_cost = labor_hours * round(random.uniform(100, 150), 2)
                total_cost = parts_cost + labor_cost
                
                maintenance_category = random.choice(['mechanical', 'electrical', 'hydraulic', 'lubrication', 'calibration'])
                priority = 'critical' if maintenance_type == 'breakdown' else random.choices(
                    ['high', 'medium', 'low'],
                    weights=[0.30, 0.50, 0.20]
                )[0]
                
                # Link to fault: corrective/breakdown should link, preventive occasionally
                related_fault_id = None
                if machine['machine_id'] in faults_by_machine:
                    if maintenance_type == 'corrective':
                        if random.random() < 0.85:  # 85% of corrective linked to faults
                            related_fault_id = random.choice(faults_by_machine[machine['machine_id']])
                    elif maintenance_type == 'breakdown':
                        if random.random() < 0.90:  # 90% of breakdowns linked to faults
                            related_fault_id = random.choice(faults_by_machine[machine['machine_id']])
                    elif maintenance_type == 'replacement' and random.random() < 0.40:
                        # 40% of replacements linked to prior faults
                        related_fault_id = random.choice(faults_by_machine[machine['machine_id']])
                
                event = {
                    'maintenance_id': self.get_next_id('MEVT'),
                    'machine_id': machine['machine_id'],
                    'line_id': machine['line_id'],
                    'factory_id': machine['factory_id'],
                    'maintenance_type': maintenance_type,
                    'maintenance_category': maintenance_category,
                    'priority': priority,
                    'scheduled_start': (event_start - timedelta(days=random.randint(1, 7))).strftime('%Y-%m-%d %H:%M:%S'),
                    'actual_start': event_start.strftime('%Y-%m-%d %H:%M:%S'),
                    'actual_end': event_end.strftime('%Y-%m-%d %H:%M:%S'),
                    'duration_minutes': int(event_duration.total_seconds() / 60),
                    'work_description': f"{maintenance_category.capitalize()} maintenance - {maintenance_type.upper()}",
                    'parts_replaced': ', '.join([f"PART-{random.randint(1000, 9999)}" for _ in range(random.randint(0, 3))]) if maintenance_type in ['corrective', 'breakdown', 'replacement'] else None,
                    'parts_cost_usd': parts_cost,
                    'labor_hours': labor_hours,
                    'labor_cost_usd': labor_cost,
                    'total_cost_usd': total_cost,
                    'technician_id': random.choice(employee_list),
                    'supervisor_id': random.choice(employee_list),
                    'related_fault_id': related_fault_id,
                    'completion_status': random.choices(
                        ['completed', 'partial', 'deferred'],
                        weights=[0.95, 0.04, 0.01]
                    )[0],
                    'notes': f"{maintenance_type.capitalize()} maintenance completed",
                    'follow_up_required': maintenance_type in ['breakdown', 'corrective'] and random.random() < 0.15,
                    'next_maintenance_due': (event_end + timedelta(days=random.randint(30, 90))).strftime('%Y-%m-%d'),
                    'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'updated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                self.data['maintenance_events'].append(event)
        
        print(f"âœ“ Generated {len(self.data['maintenance_events'])} maintenance events")
    
    def generate_all(self):
        """Generate all operations data"""
        print("\n" + "=" * 80)
        print("OPERATIONS MODULE DATA GENERATION (Using Master Registry)")
        print("=" * 80)
        
        print(f"Loaded {len(self.production_lines)} production lines from master data")
        print(f"Loaded {len(self.machines)} machines from master data")
        print(f"Loaded {len(self.sensors)} sensors from master data")
        
        self.generate_sensor_data()
        self.generate_machine_faults()  # Generate faults FIRST for SCADA linking
        self.generate_scada_data()  # SCADA links to faults
        self.generate_production_runs()  # Production runs using machine references
        self.generate_maintenance_events()  # Then maintenance can reference faults
        self.generate_sensor_health()
        
        total_records = sum(len(v) for v in self.data.values())
        print(f"\nâœ“ Generated {total_records:,d} records across {len(self.data)} tables")
        
        return self.data
    
    def save(self, filepath='genims_operational_data.json'):
        """Save generated data"""
        from pathlib import Path
        
        # Save in script directory
        if not filepath.startswith('/'):
            output_dir = Path(__file__).parent
            filepath = str(output_dir / filepath)
        
        print(f"\nSaving operational data to {filepath}...")
        with open(filepath, 'w') as f:
            json.dump(self.data, f, indent=2)
        print(f"âœ“ Saved {filepath}")

def main():
    generator = OperationsDataGenerator()
    generator.generate_all()
    generator.save()

if __name__ == '__main__':
    main()
